{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers for all targets\n",
    "Let's train classifiers for all target for different molecular represenatations and compare results. The next step will involve the optimization of hyperparameters for each classifier. `mlflow` will be used for experiment management.<br>\n",
    "\n",
    "To launch the mlflow server run:\n",
    "```bash\n",
    "cd mlflow\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# add parent directory to path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from metrics import ClassificationMetrics\n",
    "from tools import expand_array_column, train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///../mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"mol-reprs-benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parquet = Path(\"../data/2023_09_12_papyrus1k_dataset_more_params_STD_MFP_lessColumns.parquet\")\n",
    "assert path_parquet.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to precomputed fingerprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fps = Path(\"../out/fingerprints_dicts\")\n",
    "assert path_fps.exists()\n",
    "\n",
    "paths_fingerprints = list(path_fps.glob(\"*.pkl\"))\n",
    "def fps_name(fps_path): return fps_path.name.split(\".\")[0][2:]\n",
    "fps_names = [fps_name(x) for x in paths_fingerprints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and train classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(path_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_fingerprint, fps_name in tqdm(zip(paths_fingerprints, fps_names)):\n",
    "    # load fingerpriint to test and correspoinding name\n",
    "    with open(path_fingerprint, \"rb\") as f:\n",
    "        d_fps = pickle.load(f)\n",
    "\n",
    "    for target_id in tqdm(df[\"target_id\"].unique().to_list()):\n",
    "\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            mlflow.set_tag(\"model_type\", \"random_forest\")\n",
    "            mlflow.set_tag(\"dataset\", \"Papyrus1K\")\n",
    "            mlflow.set_tag(\"fingerprint\", fps_name)\n",
    "\n",
    "            mlflow.log_param(\"target_id\", target_id)\n",
    "\n",
    "            df_target = df.filter(pl.col(\"target_id\") == target_id)\n",
    "            df_target = df_target.drop([\"target_id\", \"STD_SELFIES\"])\n",
    "\n",
    "            df_target = df_target.with_columns(\n",
    "                fp = pl.col(\"STD_SMILES\").map_elements(lambda x: d_fps[x])\n",
    "            )\n",
    "            \n",
    "            # number of features\n",
    "            k = list(d_fps.keys())[0]\n",
    "            n_features = len(d_fps[k])\n",
    "            df_target = expand_array_column(df_target, \"fp\", n_features)\n",
    "\n",
    "            # Define the model with hyperparameters\n",
    "            n_estimators = 1000\n",
    "            random_state = 42\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "            metrics = train_classifier(model, df_target, target_id)\n",
    "            mlflow.log_metric(\"mcc_train\", metrics.mcc_train)\n",
    "            mlflow.log_metric(\"mcc_val\", metrics.mcc_val)\n",
    "            mlflow.log_metric(\"mcc_test\", metrics.mcc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract metrics from `mlflow` and visualize them. This allows not create additional data structure to store metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_runs = mlflow.search_runs(search_all_experiments=True)\n",
    "all_runs = mlflow.search_runs(experiment_ids=[1], order_by=[\"metrics.mcc_test DESC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df_metrics from all_runs dataframe\n",
    "df_metrics = all_runs[[\"params.target_id\", \"metrics.mcc_test\", \"metrics.mcc_train\", \"metrics.mcc_val\", \"tags.fingerprint\"]].copy()\n",
    "df_metrics = df_metrics.rename(columns={\"params.target_id\": \"target_id\", \"metrics.mcc_test\": \"mcc_test\",\n",
    "                                        \"metrics.mcc_train\": \"mcc_train\", \"metrics.mcc_val\": \"mcc_val\", \"tags.fingerprint\": \"fps_name\"})\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comparison of performance of different fingerprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"fps_name\", y=\"mcc_test\", data=df_metrics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
